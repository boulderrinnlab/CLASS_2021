---
title: "Retrieve RNA-seq reads"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(stringsAsFactors = FALSE)
library(tidyverse)
library(httr)
library(janitor)
```

Goal: to get a rational samplesheet for use in downstream analysis (ie., differential expression) and to rename the files in the format needed by nf-core/rnaseq. You need the read numbers to be a part of the filename to run with nextflow.


[Encode Query]("https://www.encodeproject.org/report/?type=Experiment&status=released&assay_slims=Transcription&assay_slims=Transcription&replicates.library.biosample.donor.organism.scientific_name=Homo+sapiens&biosample_ontology.term_name=HepG2&biosample_ontology.classification=cell+line&assay_title=total+RNA-seq&files.read_length=50&limit=all&advancedQuery=date_released:[2009-01-01%20TO%202021-12-31]")



```{bash}
# You'll want to change directory to the rnaseq directory for this following bit.
# Retrieve experiment info table
# cd to rnaseq directory (/scratch/Shares/rinnclass/<your_dir>/rnaseq)
wget -O samples.txt "https://www.encodeproject.org/report.tsv?type=Experiment&status=released&assay_slims=Transcription&assay_slims=Transcription&replicates.library.biosample.donor.organism.scientific_name=Homo+sapiens&biosample_ontology.term_name=HepG2&biosample_ontology.classification=cell+line&assay_title=total+RNA-seq&files.read_length=50&limit=all&advancedQuery=date_released:[2009-01-01%20TO%202021-12-31]"

# Retrieve fastq file urls
wget -O files.txt "https://www.encodeproject.org/batch_download/?type=Experiment&status=released&assay_slims=Transcription&assay_slims=Transcription&replicates.library.biosample.donor.organism.scientific_name=Homo+sapiens&biosample_ontology.term_name=HepG2&biosample_ontology.classification=cell+line&assay_title=total+RNA-seq&files.read_length=50&limit=all&advancedQuery=date_released:[2009-01-01%20TO%202021-12-31]"

# Now cd to the rnaseq/fastq directory 
# If the fastq directory doesn't exist, let's create it.
# You can either use the terminal and mkdir or create the directory in R.
# if(!dir.exists("rnaseq/fastq")) dir.create("rnaseq/fastq")
# Download the fastq files -- ~50 GB
# xargs -L 1 curl -O -J -L < files.txt
```

Let's look at this table in the RStudio viewer. You can see that there are a number of columns that we don't need and a number of empty columns. 

```{r}
# We'll also rename this Accession column to clarify between experiment_accession and file_accession.
samples <- read.table("rnaseq/samples.txt",
                      sep = "\t", skip = 1, header = T) %>%
  dplyr::rename(experiment_accession = Accession) 
```

We will need to clean this up as well as append new data to this (such as the md5 checksum for each file). You'll notice that there is no md5 column in this table, so that's why we need to supplement it with other data from ENCODE.

## Introduction to APIs (Application Programming Interface)

In order to exchange information between someone's database and your computer you use an API -- basically a highly specified language for interacting and retrieving the data you need.
You've done this before almost certainly as a lot of web buttons behind the scenes use an API to communicate with other databases and services that make the product work.
For that data we will use ENCODE's API to retrieve additional file information from their server.

```{r}
# First we need a function  to query their api.
# A basic API query for a REST API is made in the form of an http request (just like when you visit a website)
# Instead of sending the information to your browser though, we'll just capture this information in text format.

# We'll use for this the R library httr
library(httr)
# The basic way to retrieve data from a rest API is with a GET request. 
(resp <- GET("http://httpbin.org/get"))

# This returns to us a response object which contains information about the request made as well as some accompanying data.
# In our case we want to query the ENCODE API using the experiment accession number and request information on the md5sum, number of reads, etc.
# The base url we'll use for querying ENCODE is as follows:
# https://www.encodeproject.org/report.tsv?
# You can see from this that we expect the data to be returned in a tsv -- tab separated values format.

# Let's look at an example request for this experiment accession: ENCSR541TIG
request_url <- "https://www.encodeproject.org/report.tsv?type=File&status=released&file_format=fastq&dataset=%2Fexperiments%2FENCSR541TIG%2F&field=accession&field=read_count&field=md5sum&field=controlled_by&field=paired_end&field=paired_with&field=replicate&field=target"

# Let's break this down into your parts.
# Just like a function, we have paramters and accomanying values separated by equal signs.
# https://www.encodeproject.org/report.tsv?type=File&status=released&file_format=fastq
# Here's where we request this particular accession
# dataset=%2Fexperiments%2FENCSR541TIG%2F

# And the field parameter is where we tell it which columns or which pieces of data we want to get.
# Here we're retrieving read_count, md5sum, controlled_by, paired_end, paired_with, replicate, and target
# field=read_count&field=md5sum&field=controlled_by&field=paired_end&field=paired_with&field=replicate&field=target


# Paste this in your browswer address bar and you'll get a preview of the data we're about to retrieve.
# https://www.encodeproject.org/report.tsv?type=File&status=released&file_format=fastq&dataset=%2Fexperiments%2FENCSR541TIG%2F&field=accession&field=read_count&field=md5sum&field=controlled_by&field=paired_end&field=paired_with&field=replicate&field=target

# Let's use the httr to retreive this same data into our r session
(resp <- GET(request_url))
# This object contains the data we want, but also contains header information about the request, so let's extract just the data (body) portion
body <- read_tsv(content(resp, "text"), skip = 1)
# We can see that this now gives us a data frame of just the requested information.
```

We've written some custom helper functions specific to the ENCODE API to request exactly the information we want, since we'll make these requests multiple times -- for each experiment accession.
Here are those functions. Read through and see if you can figure out what each step is doing. The ENCODE API provides extensive documentation as to what data you can request and how to format that data to make your request. You can browse the possible requests in an interactive way using their interactive documentation: https://app.swaggerhub.com/apis-docs/encodeproject/api/basic_search

```{r}

## This will generate a request URL in the format that ENCODE requires to retrieve each of the columns listed in the field default parameter (accession, read_count, md5sum, etc.)
contstruct_query <- function(experiment_accession,
                             base_url = "https://www.encodeproject.org/report.tsv?",
                             file_format = "fastq",
                             type = "File",
                             status = "released",
                             fields = c("accession", "read_count", "md5sum",
                                        "controlled_by", "paired_end",
                                        "paired_with", "replicate", "target")) {
  query <- paste(list(paste0("type=", type),
                      paste0("status=", status),
                      paste0("file_format=", file_format),
                      paste0("dataset=%2Fexperiments%2F", experiment_accession, "%2F"),
                      map_chr(fields, ~paste0("field=", .))) %>%
                   flatten(),
                 collapse = "&")
  url <- paste0(base_url, query)
  return(url)
}

# This function actually makes the request and returns the data only (without the response headers) in a data.frame format.
encode_file_info <- function(experiment_accession,
                             base_url = "https://www.encodeproject.org/report.tsv?",
                             file_format = "fastq",
                             type = "File",
                             status = "released",
                             fields = c("accession", "read_count", "md5sum",
                                        "controlled_by", "paired_end",
                                        "paired_with", "replicate", "target")) {
  path <- "report.tsv?"
  base_url <- modify_url("https://www.encodeproject.org/", path = path)
  url <- contstruct_query(experiment_accession,
                          base_url = base_url,
                          file_format,
                          type,
                          status,
                          fields)
  resp <- GET(url)
  if (http_error(resp)) {
    error_message <- content(resp, type = "text/html", encoding = "UTF-8") %>%
      xml_find_all("//p") %>%
      xml_text() %>%
      first()
    stop(
      sprintf(
        "ENCODE API request failed [%s]\n%s",
        status_code(resp),
        error_message
      ),
      call. = FALSE
    )
  }
  
  if (http_type(resp) != "text/tsv") {
    stop("API did not return text/tsv", call. = FALSE)
  }
  body <- read_tsv(content(resp, "text"), skip = 1) %>%
    clean_names()
  return(body)
}
```

We can now test that this function delivers what we want it to using the same accession we used previously.
Note that since all of the parameters except the accession number have default values, if we want the defaults, we
only need to provide the ENCODE accession of the experiment we want the file info for.

```{r}
dat <- encode_file_info("ENCSR541TIG")
```

## Introduction to map

There is one other function we need to learn about before we make the queries to the ENCODE API, which is the map function from the purrr package.
This allows us to query each experiment accession and load the data we retrieve into the same data.frame that contains the sample info.
It's very similar to sapply or lapply, but is more consisten with tidyverse syntax and allows us to do lapply inside a data.frame & with pipe syntax.

```{r}
# In this example we'll take the digits 1 through 10 and "map" each to the rnorm function. 
map_example <- 1:10 %>%
  map(rnorm, n = 10)
?rnorm
# It returns a nested list. 
map_example[[1]]
map_example[[1]][[1]]

# We'll come back to this concept of nesting...
```

We can use map to call this encode_file_info function for each experiment accession and return each data.frame into a new column in our samples data.frame.

```{r}
samples <- samples %>%
  mutate(file_info = map(experiment_accession, ~ encode_file_info(.x)))

# Note that in this new column we have a bunch of data.frames -- nested in our samples data.frame.
# Let's retrieve one as an example
file_info <- samples$file_info[[1]]
```

This is a bit hard to read in this format, so we can unnest the data.frames in the file_info column using the unnest command.
This will duplicate the remaining columns to match the number of lines in the nested data.frame.

```{r}
# We also need to tell it which column we want to unnest.
samples <- samples %>%
  unnest(cols = file_info)
```

Now we have all the information we neeed in this data.frame and we just need to clean it up.

```{r}
# Let's number our replicates and create a new column called sample id where we join the experiment accesion and the rep number
samples <- samples %>%
  group_by(experiment_accession) %>%
  mutate(rep_number = as.numeric(factor(replicate))) %>%
  # ?unite -- will combine two data columns into one. Be careful, by default it will remove the columns you're uniting.
  unite(sample_id, experiment_accession, rep_number, sep = "_rep")
```

Essentially we're creating the file names for each fastq so that they're understandable.

```{r}
# We're just selecting a subset of columns and 
samples <- samples %>%
   dplyr::select(sample_id, accession, Assay.title,
                Biosample.summary, md5sum, paired_end_identifier) %>%
  # Note that we're not removing the original columns
  unite(fastq_file, sample_id, paired_end_identifier, sep = "_read", remove = F)
```

Now let's make the full filename for the fastq files. For the nf-core/rnaseq pipeline, the paired-end reads need to be named with the read number in the filename. 

```{r}
samples <- samples %>%
  mutate(fq_extension = ".fastq.gz") %>%
  unite(fastq_file, fastq_file, fq_extension, sep = "", remove = F) %>%
  # This original file column will be used along with the new name column to rename the fastq files.
  unite(original_file, accession, fq_extension, sep = "")
```

We broke this down into parts, so you can understand what is happening, but just note that you can write all of this in one block and read it like a sentence.

```{r}
samples <- read.table("rnaseq/samples.txt",
                      sep = "\t", skip = 1, header = T) %>%
  dplyr::rename(experiment_accession = Accession) %>%
  mutate(file_info = map(experiment_accession, ~ encode_file_info(.x))) %>%
  unnest(file_info) %>% 
  group_by(experiment_accession) %>%
  mutate(rep_number = as.numeric(factor(replicate))) %>%
  unite(sample_id, experiment_accession, rep_number, sep = "_rep") %>%
  dplyr::select(sample_id, accession, Assay.title,
                Biosample.summary, md5sum, paired_end_identifier) %>%
  unite(fastq_file, sample_id, paired_end_identifier, sep = "_read", remove = F) %>%
  mutate(fq_extension = ".fastq.gz") %>%
  unite(fastq_file, fastq_file, fq_extension, sep = "", remove = F) %>%
  unite(original_file, accession, fq_extension, sep = "")
```

This cleaned up version of the samplesheet is good to go, but we now need to make a script to rename the originally downloaded fastq files to our new names.
We can "write" this script in a data.frame. 

```{r}
# Rename the fastq files so that they contain the sample ID.
rename_script <- samples %>%
  dplyr::select(fastq_file, original_file) %>%
  mutate(command = "mv") %>%
  unite(command, command, original_file, fastq_file, sep = " ")
# The result of this is that each row is a bash command.

# We can write this out as a bash script with ?write_lines 
# We include a shebang header line so that the script is interpreted by bash.

write_lines(c("#!/bin/bash", rename_script$command), "rnaseq/fastq/rename.sh")

# Here we use an R command to call bash and cd into that directory, then make the file executable, and then run it.
# system("cd rnaseq/fastq; chmod u+x rename.sh; ./rename.sh")
```

Additionally from all of this information we've gathered we can create a text file to run the md5sum check.

```{r}
# Let's create an md5.txt to run the checksums
md5 <- samples %>% 
  dplyr::select(md5sum, fastq_file) %>%
  unite(line, md5sum, fastq_file, sep = "  ")
write_lines(md5$line, "rnaseq/fastq/md5.txt")
# Now let's run it.
# system("cd rnaseq/fastq; md5sum -c md5.txt")
```

Finally, we can write out a nicely formatted sample sheet that we will use downstream for further analysis of the read counts in R.

```{r}
# Let's create the sample sheet that we will use later
# to do the RNA-seq analysis in R.
samples <- samples %>%
  dplyr::rename(fastq = fastq_file,
                seq_type = Assay.title,
                sample_name = Biosample.summary) %>%
  # The minus sign will remove this column -- which we no longer need.
  dplyr::select(-original_file) 


# Now that we have it cleaned up, let's create one line for each replicate where the fastq read 1 and read 2 are in the same row.
# For this we will use the pivot wider function
# We need to tell the pivot_wider function which unique column combinations will specify each new row. 
samplesheet <- samples
samplesheet <- samplesheet %>%
  pivot_wider(id_cols = c("sample_id", "seq_type", "sample_name"),
              names_from = paired_end_identifier,
              values_from = c("fastq", "md5sum"))


# Harmonize the sample names with the design file.
samplesheet <- samplesheet %>%
  mutate(condition = gsub(" ", "_", sample_name) %>% tolower()) %>%
  separate(sample_id, into = c("experiment_accession", "replicate"), 
           remove = FALSE, sep = "_") %>%
  mutate(replicate = gsub("rep", "R", replicate)) %>%
  unite(sample_name, condition, replicate, sep = "_", remove = FALSE)

samplesheet$condition[samplesheet$condition == "hepg2"] <- "hepg2_total"
samplesheet <- samplesheet %>%
  mutate(cell_type = "hepg2",
         condition = gsub("hepg2_", "", condition)) %>%
  dplyr::select(sample_id, sample_name, replicate, condition,
                cell_type, seq_type, fastq_1, fastq_2, md5sum_1,
                md5sum_2)

write_csv(samplesheet, "rnaseq/samplesheet.csv")
```

We also need to make a design file for the nf-core/rnaseq

The design file needs to be in a specific format (as we saw with nf-core/chipseq)
It needs the following columns:
group,replicate,fastq_1,fastq_2,strandedness

```{r}
# This will have the following columns:
# group,replicate,fastq_1,fastq_2,strandedness
# The group will specify the experimental condition 
# We could use the experiment accesion or we could use the 
# sample_name.
# Let's create a group column using mutate -- and we'll clean up the names
# There's spaces in the names currently and we need to get rid of those.
design <- samplesheet %>%
  # We also need to add the proper file path
  mutate(group = gsub(" ", "_", sample_name) %>% tolower(),
         strandedness = "reverse",
         fastq_1 = paste0("/scratch/Shares/rinnclass/data/rnaseq_fastq/", fastq_1),
         fastq_2 = paste0("/scratch/Shares/rinnclass/data/rnaseq_fastq/", fastq_2)) %>%
  # We have the replicate number already, but it's just a part of the sample id
  # We can use the separate function (opposite of unite) to retrieve it.
  separate(sample_id, into = c("experiment_accession", "replicate"), sep = "_", remove = FALSE) %>%
  mutate(replicate = gsub("rep", "", replicate)) %>%
  # Now we gather just the columns we need
  dplyr::select(group, replicate, fastq_1, fastq_2, strandedness)


# remove r1/r2 from names

design <- design %>%
  mutate(group = gsub("_r1", "", group),
         group = gsub("_r2", "", group))

# sort otherwise error during running
design <- design %>% 
  arrange(group, replicate)


design <- design %>% 
  arrange(group, replicate)

all(sapply(design$fastq_1, file.exists))
all(sapply(design$fastq_2, file.exists))

# Now we can write this out for input into nextflow
write_csv(design, "rnaseq/design.csv")

file.exists(design$fastq_1[[1]])

```


Now we have the raw files downloaded and the samplesheet needed for downstream analyses (ex, differential expression). So the next step is to run nf-core/rnaseq on these samples.
We'll do this in the 14-1 R Markdown.


