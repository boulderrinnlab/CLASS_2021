---
title: "Nextflow"
author: "JR"
date: "11/10/2020"
output: html_document
---

Today we will install nextflow and install the nf-core/chip-seq pipeline. This way we can
run hundreds of ChIP-seq files simultaneously through, alignments, qc, peak calling
-- all the stuff you would ever want (even bigwig files for browsing raw data).

Nextflow has amazing documentation and a good place to start is here:

https://www.nextflow.io/docs/latest/getstarted.html

You can go over what is included in the pipeline (everything you need :) here:

https://nf-co.re/chipseq

Scroll down to the bottom of the link above and see that you will already get
a lot of results!
 

****************
Step 1 Install:
****************

Nextflow will install itself with this simple commmand below. However, you will
want to think about where to install it. When you know where you want it (usually
home directory or fairly high level up).

A reasonable place to install it is in a "bin" directory within your home directory

/Users/<identikey>/bin/nextflow

Alrighty, give it a go:

```{bash}
# If you'd like to put it in your bin directory
# make one if you don't have one
cd ~
mkdir bin
cd bin

# Then install nextflow
curl -s https://get.nextflow.io | bash
```

Nice it's installed just like that! curl went and got a bash script (silent -s)
and the results of that query were piped to bash which runs the script to install itself.

This is nifty, but the fact that you can run a script from the internet highlights that you
should be careful that you trust the website, etc.

If you ever want to update nextflow just run the above. At the time of this doc
it is at: v20.10.0

********************************
Step 2: Add nextflow to $PATH
********************************

The path is a default place the computer will look for commands. Imagine you
had to tell Bash where the ls command is?

By the way, how to you tell where the ls command is?

If you didn't have the PATH environment variable you would have to type something like this

/usr/bin/ls to list files instead of just ls

So that path is an important aspect of unix/bash that you will never really hear
about until it becomes a bug :) Just to be safe let's add nextflow to our $PATH

```{bash}

echo $PATH
echo $PATH | tr ":" "\n"
# kinda hard to read with : seperated file
# we can make it easier to read with TRANSFORM (tr) a powerful bash command to
# repalce and find text. 
# echo is just going to print out the $PATH variable and pipe to transform to
# take the : and make it a new line (\n) --- ahhh so much nicer to read!

# Now let's add it to our .profile file which will load each time you login to the terminal
~/.profile

```


Luckily, we don't need to add each individual program to the PATH,
rather we can now just add your new bin file to the PATH.

```{bash}
# To append a directory to PATH, we just need to overwrite the path variable
# To assign a variable in bash the assignment operator is the equals sign. 
# When assigning a variable you just write the variable name.
# Typically environment variables in bash are written as all caps with no special characters
# When referring to the contents saved in an environment variable, the $ is used
PATH=$PATH:~/bin
```

This will change the PATH environment variable during this session only,
but we want this to be added to the environment variable each time that 
we start a shell session. Therefore, we can add it to the configuration file
that is run each time you login to a shell session.

```{bash}
nano .profile
# Add the line
PATH=$PATH:~/bin
# Then save this. 
# This file is loaded each time your terminal starts up.
# Therefore, it is not currently loaded
# To load this in the current session
source ~/.profile

# Now check that nextflow can be run without refering to it's location
nextflow -version
```

Sweet, that's it. We've successfully installed nextflow.


Alright we have nextflow installed and we never have to worry about fiji finding
the commands again!


****************
Step 3: Install nf-core/chipseq pipeline
****************

Now we want to install the chipseq pipeline from NF-core. The cool thing about 
this set up is essentially you are going to clone the latest github for chipseq
by default. Simply run:


```
nextflow pull nf-core/chipseq
```

Next flow takes care of managing all the packages that need to be installed and 
the versions that were installed etc. So this container is 100% reproducible.

If you want a specific version you can use the flag to call that version.
At the time of this document chipseq is at 1.2.1. 

```
nextflow pull -r 1.2.1 nf-core/chipseq
```

Whenever the pipeline is run, it actually does this step behind the scenes,
so you don't actually need to do this in order to have the chipseq pipeline install.
This means that if you want to run an older version, you can just indicate that when
you're running that pipeline and it will install that version if it's not 
already installed.


*********************
Step 4: Config_FILE
*********************

Ok so we have next flow and the Chip seeker pipeline on our server. Since Nextflow
is system agnostic and it can be run on many different system types, 
we need to tell nextflow how to run on fiji.

To this end we need to make a nextflow.config file. Here next flow will look for the:

executor : here we see it is slurm (as we will describe more below). It stands
for Simple Linux Utility for Resource Management. Basically a simple job scheduler.

queue : there is a long and short queue (<24h), they describe themselves that one queue
is short or faster, and the other is longer. 

memory : your telling fiji or your server, computer etc how much RAM or memory to
use for the nextflow process. This is something to think about and consult with your IT team.
You don't want to over load the server or your computer!

maxforks : this tells nextflow how many processes can be run in parallel. Let's 
say you had 10 fastq files to run through a pipeline you can speed up the process
of running 10 tasks in parallel!

Here is all this put together in a simple few lines that schedules how nextflow
will communicate with your machine and how to move forward with it's core processes.

10 processes simulanteously -- so if you have 10000 fastqs it will process 10 BWA
alignments at a time. 

# Let's start to setup our first nextflow run

```{bash}
cd /scratch/Shares/rinnclass/<name>/
mkdir first_chipseq
cd first_chipseq

# Now let's create a nextflow.config file
nano nextflow.config
# Then paste in what's below
```


```{bash}
process {
  executor='slurm'
  queue='short'
  memory='32 GB'
  maxForks=10
}
```

Above is a typical nextflow.config file that is needed to run nextflow on fiji.

Note that the sbatch set up used less RAM etc. That is because the sbatch is 
"controling the job flow" and doesn't need as much juice to do send and manage
jobs. However, nextflow is calling on the server seperately for it's memory usage.
This means nextflow will be running with more juice ...


********************************
Step 5: SLURM - run.sh
********************************

We could run nextflow directly from the command line, but since the total
time to compute for the nextflow chipseq pipeline can be hours to days,
and the job will stop running when you exit your terminal, we need a different 
solution. We could use screen, but that will result in the nextflow process running
on the login-node. Instead we should submit a job to slurm that will
run the nextflow process and orchestrate the execution of jobs.


The chunk below is an example of how we will invoke nextflow using a slurm job on fiji.


Essentiall the run.sh file is everythign we need to set up all the details of the run.  These are slurm instructions and nextflow learned it would be in slurm via the config file. We will use SBATCH to submit batch instructions to slurm. 

In otherwords: When the job allocation is finally granted for the sbatch script,
the nextflow process will start running on one of the compute nodes.

First let's look at the sbatch / slurm communication set up. Each aspect is 
described with a # below.

```{BASH}

#!/bin/bash
#SBATCH -p short
#SBATCH --job-name=Hepg2_Pol_test
#SBATCH --mail-type=END,FAIL
#SBATCH --mail-user=john.rinn@colorado.edu


### These lines are telling the slurm scheduler what resources we need. Here we're saying we
### want to be in the short queue (For jobs that take less than 24 hrs to run. Name of the job, who to email etc...

#SBATCH --nodes=1
### Fiji has multiple nodes and you will rarely want to run a job across more 
### than one node. 

#SBATCH --ntasks=1
#### This is how many cpus you're requesting. We wil typically
#### leave this at 1 so the nextflow runs only on one cpu (single-threaded). 
#### For some software, they can by run multicore and you may want more that one cpu.


#SBATCH --mem=6gb

#### Simply setting how much RAM memory you're requesting for your job. This is an important consideration
#### depending on how much RAM your software uses to do the compute task.
  

#SBATCH --time=10:00:00

## The other noteable is the "WALL CLOCK" 
## THIS IS WHERE GOOD MANNERS come into play. You want to test this out on a few
## files and then think about how it will scale. This run.sh file is for thousadnds
## of FASTQ files, we will change the wall clock.


#### We also want to follow standard error and output. This will allow us to track
#### the progress of the run. 


#SBATCH --output=nextflow.out
#SBATCH --error=nextflow.err

```

So above SBATCH organized all the instructions needed for slurm to scehdule the job.
However, now we need set the file paths for next flow. We are using nextflow
command language that is in the documentation. 


---- Setting the nextflow parameter and file paths ----

Now that we have SBATCH all set up we need to set the nextflow parameters for the
job. 


Here is the second half of the run.sh file needed below. The description of each
follows after the chunk.

```{bash}
# Make a run.sh
nano run.sh
# Paste in what's below
```


```{BASH}
#!/bin/bash
#SBATCH -p short
#SBATCH --job-name=Hepg2_Pol_test
#SBATCH --mail-type=END,FAIL
#SBATCH --mail-user=john.rinn@colorado.edu

pwd; hostname; date
echo "Lets do chipseq"

module load singularity/3.1.1

nextflow run nf-core/chipseq -r 1.2.1 \
-profile singularity \
--single_end \
--input design.csv \
--fasta /Shares/rinn_class/data/genomes/human/gencode/v32/GRCh38.p13.genome.fa \
--gtf /Shares/rinn_class/data/genomes/human/gencode/v32/gencode.v32.annotation.gtf \
--macs_gsize 3.2e9 \
--blacklist /scratch/Shares/rinnclass/data/hg38-blacklist.v2.bed \
--email john.rinn@colorado.edu \
-resume \
-c nextflow.config

date



### add the sbatch information to this above and make run.sh file in your directory
```

Each line is a command ended by \

The backslash is a way to write multi-line bash commands that will be interpreted by the shell as one line.

The first step is telling the pathway, hostname and date of where and when job was run.
the echo command is sort of silly and just let's you know SBATCH was successful!

module load singularity/3.1.1 is going to load singularity and tell bash that it
is using singularity:

Singularity: This is telling nextflow that instead of installing all the software locally,
it should go and retrieve the software from a singularity container that contains everything
needed to run the pipeline. 

Profile: this has a single flag is for an abbreviation of a command. Double flags
are specifying directly to the command name. This tells the
server to use the singularity container for instructions on running the pipeline
that are set up by nextflow commands.

--Single end: the defualt is paired end for nextflow, if the data is single end
read then we need to tell nextflow that.

-- input: is the design file so next flow knows which are controls, replicates etc
more on this below.

-- fasta: one of the initial steps in the nextflow pipelien is alining the reads to
the genome of interest. So to make sure that is precise and reporducible you 
provide the file path to the genome (in our case it is preplaced in file path).

-- gtf: this is the file of annotations in the human genome. Here we will use 
Genocode. Gencode's website provides a GTF of whatever release you prefer here:

https://www.gencodegenes.org/human/

-- macs_gsize: this is the effective genome size that is required by the MACS 
peak calling algorithm in the nextflow pipeline. The genome is about 3 billion
bases is what we are saying here. 

-- blacklist: the reason we didn't 3B above is that many regions of the genome are not good
to align to for various reasons (low complexity etc). This is telling nextflow what
regions of your genome are bad and it will stay away from these coordinates.

-- email so nextflow can email you status on your job (SLURM will too :)

-- resume: is nextflow command that if there is a failure you don't have to start
at the beginign fo the pipeline each time.

-c abrreviation for config file.

date: when the pipeline finishes it will print the bash date command (we used above)


*******************************************
Step 6:Running and Checking on slurm jobs
*******************************************

First thing we want to do is "run" a .sh file. Since we set this up in SBATCH we
simply type:

Don't run yet though
```
sbatch run.sh
```
This will have sbatch send the scripts in the run.sh file to slurm to run them. 


--- what jobs are you running? You often want to see what job is running how long it is taking and other aspects. To that end we can use 'squeue' to see what is running

```
squeue -u identikey
```

the -u flag is for user.
examine the information provided and google the column headers for more info.

---- canceling jobs


Let's say you accidently hit the run button and want to cancel immediately.

'scancel' is the command

```
squeue -u identikey
scancel jobid
scancel -u identikey #cancels all running jobs
```

--- canceling multiple jobs:

```
squeue -u identikey | grep commonjobid# | awk '{print $1}' | xargs -n 1 scancel

squeue -u jori2700  | grep 591 | awk '{print $1}' | xargs -n 1 scancel
```

Here we are using some bash to grab all the jobs running. They will typically have a common number (591 in example above -- would have aloso worked with just 5).

Grep finds all your job id matches, then awk prints them, xargs is then going 
to perform scancel on the output of awk, the -n is telling xargs how many arguments will follow. In this case just 1 -- scancel.

Voila your jobs are gone :)


**********************
Step 7: Design file
**********************

Nextflow documentation has a clear set up for the Chipseq pipeline. 
You must have the folowing columns (seperated by ',')

```
group,replicate,fastq_1,fastq_2,antibody,control
```


GROUP: the name of the gene targeted or sample information (e.g. POL2)

REPLICATE: if you have replicates you number them 1,2 .... in each row. If you 
have only one, you need to type in 1.

fastq_1: file path to the fastq files you downloaded from ENCODE.
fastq_2: if you have dual end reads the second read fastq file path.

ANTIBODY: this is the target and same a group name for non-control samples.

CONTROL: in our case this is input DNA from ChIP. ENCODE let us know what the 
control accession is. 

NOTE: the controls still need to be places as a 'group' entry. Howevever, their
'control' column is empty.


********************************
Step 8: Test run of design file!
********************************

You will need these files -- and change the file paths in the design file below
to where the fastq files are for you. You can download them with these links and wget:

https://www.encodeproject.org/files/ENCFF210PXS/@@download/NCFF210PXS.fastq.gz
https://www.encodeproject.org/files/ENCFF525AYL/@@download/ENCFF525AYL.fastq.gz
https://www.encodeproject.org/files/ENCFF162ADN/@@download/ENCFF162ADNP.fastq.gz



Here is a mini design file -- you will have to change the file path to the fastq
files accordingly. 

I am putting then design below as a tab serpated file. Can you use transmute 
to put it back to comma seperated?

```
group	replicate	fastq_1	fastq_2	antibody	control
ASH2L	1	../data/ENCFF210PXS.fastq.gz		ASH2L	ENCSR055XHN
ASH2L	2	../fastq/ENCFF525AYL.fastq.gz		ASH2L	ENCSR055XHN
ENCSR055XHN	1	../fastq/ENCFF162ADN.fastq.gz
```


Hint:

```
cat design.csv | tr '\t' ',' > desgin2.csv
```


group,replicate,fastq_1,fastq_2,antibody,control
ASH2L,1,../../data/ENCFF210PXS.fastq.gz,,ASH2L,ENCSR055XHN
ASH2L,2,../../data/ENCFF525AYL.fastq.gz,,ASH2L,ENCSR055XHN
ENCSR055XHN,1,../../data/ENCFF162ADN.fastq.gz,,,

NOTE: remember to make sure the file path is correct to the fastq on your computer.
here i am saying the fastq directory is one directory above then the path to the
file name.

Once you have all set:

```
sbatch run.sh
tail -f nextflow.out
```

This will run the pipeline and tail -f allows you to follow the end of the nextflow
output as it is going.

Go check out all the results in the results folder created by nextflow! In the 
next class we will go over all the output files and how to visualize the data
produced (bigWig and peak_files)

Excercise: Make a design file for a diferent DNA binding protein in the encode
dowload list. We can debug all the problems in class.






## Homework Fun ##

To start Run each of these lines in a row. 
```{BASH}

mkdir time_script
cd time_script

cat >> what-time-is-it.sh << 'EOF'
#!/bin/bash

current_time=$(date | tr -s " " "\t" | cut -f 4 | cut -d ":" -f 1,2)
#notice use of transmute (tr) and cut -- these are just grabbing the information
#bash date command output looks like: Sun Nov 15 18:06:10 MST 2020. Hint cut -f 4
# grabs the 4th item which is the time.

# Exercise see how transmute and cut grab the information more succinctly.

echo "The time is $current_time.
I'm glad to see you're making good use of it :)"

# this is just adding silly text to output with the time.


# EOF is End of File we set on the first line.
EOF

chmod +x what-time-is-it.sh

# chmod changes the permissions to a file, the +x gives it "executable" permission
# to go from shell to Kernel.

ls
cat what-time-is-it.sh

## Notice it wrote out the file what-time-is-it with the "cat >>" command.
```

Ok so we have a time telling script that only works in the current directory:

This is where I made it:

/Users/jori2700/CLASS/time_script

So now we can add this to $PATH and run the script whenever just like ls, cat etc.

First we are going to add the .sh script to our $PATH temporarily.

```{BASH}

pwd
#copy and paste path to the directoy the .sh script is in


export PATH="$PATH:/Users/Users/jori2700/CLASS/time_script"
what_time_is_it.sh #(notice we don't need the ./ now that the path is set)

```


Now how to permenantly add to you $PATH

```{BASH}

echo 'export PATH="$PATH:/Users/jori2700/CLASS/time_script/"' >> ~/.bash_profile
# nice let's take a look
echo $PATH | tr ":" "\n"
# we need to activate our new $PATH with
source ~/.bash_profile

cd anywhere
sh what-time-is-it.sh
```

Voila we can use the script anytime. Also this is a nice idea to have new scripts
etc in this folder as they will automatically be in $PATH now. To run a .sh file
you want to type "sh filename" in this case sh waht-time-is-it.


